% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/embeddings.R
\name{bert_embeddings}
\alias{bert_embeddings}
\title{Create BERT Embeddings}
\usage{
bert_embeddings(
  embedding_size,
  max_position_embeddings,
  vocab_size,
  token_type_vocab_size = 2L,
  hidden_dropout = 0.1
)
}
\description{
There are three components to the input embeddings in a BERT model: the
embedding of the tokens themselves, the segment ("token type") embedding, and
the position (token index) embedding. This function sets up the embedding
layer for all three of these.
}
\details{
This will eventually inherit from a higher-level function.
}
\section{Shape}{

# still need to fill this part out!
  Inputs:

  - input_ids: \eqn{(input_size, *)}

  - token_type_ids: \eqn{(output_size, *)}

  Optional input parameter `seq_len_cap` to limit number of positions
  (tokens) considered.

  Output:

  - \eqn{(embedding_size, *)}
}

\examples{

}
