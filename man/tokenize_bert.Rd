% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tokenize.R
\name{tokenize_bert}
\alias{tokenize_bert}
\title{Prepare Text for a BERT Model}
\usage{
tokenize_bert(
  text,
  n_tokens = 64L,
  simplify = FALSE,
  pad_token = "[PAD]",
  cls_token = "[CLS]",
  sep_token = "[SEP]",
  tokenizer = wordpiece::wordpiece_tokenize,
  vocab = wordpiece.data::wordpiece_vocab(),
  ...
)
}
\arguments{
\item{text}{Character or list of characters; the text to prepare. Right now
only character or lists of length-1 characters are supported, but we will
soon also allow the text to be provided as a list of length-N character
vectors (usually 1 or 2), which will be combined but separated with
\code{sep_token}.}

\item{n_tokens}{Integer scalar; the number of tokens expected for each
example.}

\item{simplify}{Logical scalar; whether to return the result as a list
(\code{FALSE}), or as a matrix. The matrix returned is currently
\code{n_tokens} rows by \code{length(text)} columns, but we plan to
transpose that in an upcoming change to the overall package API.}

\item{pad_token}{Character scalar; the token to use for padding. Must be
present in the supplied vocabulary.}

\item{cls_token}{Character scalar; the token to use at the start of each
example. Must be present in the supplied vocabulary, or \code{NULL}.}

\item{sep_token}{Character scalar; the token to use at the end of each
segment within each example. Must be present in the supplied vocabulary, or
\code{NULL}.}

\item{tokenizer}{The tokenizer function to use to break up the text. It must
have a \code{vocab} argument.}

\item{vocab}{The vocabulary to use to tokenize the text.}

\item{...}{Additional arguments passed on to the tokenizer.}
}
\value{
A list of token indices, or a matrix.
}
\description{
To be used in a BERT-style model, text must be tokenized. In addition, text
is optionally preceded by a \code{cls_token}, and segments are ended with a
\code{sep_token}. Finally each example must be padded with a
\code{pad_token}, or truncated if necessary (preserving the wrapper tokens).
Many use cases use a matrix of tokens x examples, which can be extracted
directly with the \code{simplify} argument.
}
\examples{
tokenize_bert(c("A first example.", "Another one."))
}
